import streamlit as st
import pandas as pd
import plotly.express as px
import math
import numpy as np
from services.db import get_db

def _safe_sum(df, col):
    if df is None or df.empty or col not in df.columns:
        return 0.0
    s = df[col]
    if pd.api.types.is_numeric_dtype(s):
        return float(pd.to_numeric(s, errors="coerce").sum(skipna=True))
    s = (
        s.astype(str)
        .str.replace(r"[^0-9\.\-]", "", regex=True)
        .replace("", pd.NA)
    )
    return float(pd.to_numeric(s, errors="coerce").sum(skipna=True) or 0.0)


def proper_round(x):
    """æ ‡å‡†çš„å››èˆäº”å…¥æ–¹æ³•ï¼Œå¤„ç†æµ®ç‚¹æ•°ç²¾åº¦é—®é¢˜"""
    if pd.isna(x):
        return x
    # å¤„ç†æµ®ç‚¹æ•°ç²¾åº¦é—®é¢˜
    x_rounded = round(x, 10)  # å…ˆèˆå…¥åˆ°10ä½å°æ•°æ¶ˆé™¤ç²¾åº¦è¯¯å·®
    return math.floor(x_rounded + 0.5)


def persisting_multiselect(label, options, key, default=None, width_chars=None):
    if key not in st.session_state:
        st.session_state[key] = default or []

    # === ä¿®æ”¹ï¼šæ·»åŠ è‡ªå®šä¹‰å®½åº¦å‚æ•° ===
    if width_chars is None:
        # é»˜è®¤å®½åº¦ä¸ºæ ‡ç­¾é•¿åº¦+1å­—ç¬¦
        label_width = len(label)
        min_width = label_width + 1
    else:
        # ä½¿ç”¨è‡ªå®šä¹‰å®½åº¦
        min_width = width_chars

    st.markdown(f"""
    <style>
        /* å¼ºåˆ¶è®¾ç½®å¤šé€‰æ¡†å®½åº¦ */
        [data-testid*="{key}"] {{
            width: {min_width}ch !important;
            min-width: {min_width}ch !important;
        }}
        [data-testid*="{key}"] > div {{
            width: {min_width}ch !important;
            min-width: {min_width}ch !important;
        }}
        [data-testid*="{key}"] [data-baseweb="select"] {{
            width: {min_width}ch !important;
            min-width: {min_width}ch !important;
        }}
        [data-testid*="{key}"] [data-baseweb="select"] > div {{
            width: {min_width}ch !important;
            min-width: {min_width}ch !important;
        }}
    </style>
    """, unsafe_allow_html=True)

    return st.multiselect(label, options, default=st.session_state[key], key=key)


# === é¢„åŠ è½½æ‰€æœ‰æ•°æ® ===


@st.cache_data(ttl=600, show_spinner=False)
def _prepare_inventory_grouped(inv: pd.DataFrame):
    if inv is None or inv.empty:
        return pd.DataFrame(), None

    df = inv.copy()

    if "source_date" in df.columns:
        df["date"] = pd.to_datetime(df["source_date"], errors="coerce")
    else:
        return pd.DataFrame(), None

    # Category åˆ—
    if "Categories" in df.columns:
        df["Category"] = df["Categories"].astype(str)
    elif "Category" in df.columns:
        df["Category"] = df["Category"].astype(str)
    else:
        df["Category"] = "Unknown"

    # === ç”¨ catalogue ç°ç®— - åº”ç”¨æ–°çš„inventory valueè®¡ç®—é€»è¾‘ ===
    # 1. è¿‡æ»¤æ‰ Current Quantity Vie Market & Bar ä¸ºè´Ÿæ•°æˆ–0çš„è¡Œ
    df["Quantity"] = pd.to_numeric(df["Current Quantity Vie Market & Bar"], errors="coerce")
    mask = (df["Quantity"] > 0)  # åªä¿ç•™æ­£æ•°
    df = df[mask].copy()

    if df.empty:
        return pd.DataFrame(), None

    # 2. æŠŠ Default Unit Cost ä¸ºç©ºçš„å€¼è¡¥ä¸º0
    df["UnitCost"] = pd.to_numeric(df["Default Unit Cost"], errors="coerce").fillna(0)

    # 3. è®¡ç®— inventory value: Default Unit Cost * Current Quantity Vie Market & Bar
    df["Inventory Value"] = df["UnitCost"] * df["Quantity"]

    # å››èˆäº”å…¥ä¿ç•™æ•´æ•°
    df["Inventory Value"] = df["Inventory Value"].apply(lambda x: proper_round(x) if not pd.isna(x) else 0)

    # ä¿ç•™å…¶ä»–è®¡ç®—ï¼ˆå¦‚æœéœ€è¦ï¼‰
    df["Price"] = pd.to_numeric(df.get("Price", 0), errors="coerce").fillna(0)

    # ä¿®å¤ï¼šæ£€æŸ¥ TaxFlag åˆ—æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»ºé»˜è®¤å€¼
    if "TaxFlag" not in df.columns:
        df["TaxFlag"] = "N"  # é»˜è®¤å€¼ï¼Œå‡è®¾ä¸å«ç¨

    def calc_retail(row):
        try:
            O, AA, tax = row["Price"], row["Quantity"], row["TaxFlag"]
            return (O / 11 * 10) * AA if tax == "Y" else O * AA
        except KeyError:
            # å¦‚æœåˆ—ä¸å­˜åœ¨ï¼Œç›´æ¥è®¡ç®— Price * Quantity
            return row["Price"] * row["Quantity"]

    df["Retail Total"] = df.apply(calc_retail, axis=1)
    df["Profit"] = df["Retail Total"] - df["Inventory Value"]

    # èšåˆ
    g = (
        df.groupby(["date", "Category"], as_index=False)[["Inventory Value", "Profit"]]
        .sum(min_count=1)
    )

    latest_date = g["date"].max() if not g.empty else None
    return g, latest_date


# === é¢„åŠ è½½æ‰€æœ‰æ•°æ® ===
@st.cache_data(ttl=600, show_spinner=False)
def preload_all_data():
    """é¢„åŠ è½½æ‰€æœ‰éœ€è¦çš„æ•°æ®"""
    db = get_db()

    # åŠ è½½äº¤æ˜“æ•°æ® - ä¿®å¤ï¼šç¡®ä¿åŒ…å«æ‰€æœ‰åˆ†ç±»ï¼ŒåŒ…æ‹¬ç©ºåˆ†ç±»
    daily_sql = """
    WITH transaction_totals AS (
        SELECT 
            date(Datetime) AS date,
            [Transaction ID] AS txn_id,
            SUM([Gross Sales]) AS total_gross_sales,
            SUM(COALESCE(CAST(REPLACE(REPLACE([Tax], '$', ''), ',', '') AS REAL), 0)) AS total_tax,
            SUM(Qty) AS total_qty
        FROM transactions
        GROUP BY date, [Transaction ID]
    )
    SELECT
        date,
        SUM(ROUND(total_gross_sales - total_tax, 2)) AS net_sales_with_tax,
        SUM(total_gross_sales) AS gross_sales,
        SUM(total_tax) AS total_tax,
        COUNT(DISTINCT txn_id) AS transactions,
        CASE 
            WHEN COUNT(DISTINCT txn_id) > 0 
            THEN SUM(ROUND(total_gross_sales - total_tax, 2)) * 1.0 / COUNT(DISTINCT txn_id)
            ELSE 0 
        END AS avg_txn,
        SUM(total_qty) AS qty
    FROM transaction_totals
    GROUP BY date
    ORDER BY date;
    """

    category_sql = """
    WITH category_transactions AS (
        SELECT 
            date(Datetime) AS date,
            -- ä¿®å¤ï¼šå¤„ç†ç©ºåˆ†ç±»ï¼Œç¡®ä¿æ‰€æœ‰æ•°æ®éƒ½è¢«åŒ…å«
            CASE 
                WHEN Category IS NULL OR TRIM(Category) = '' THEN 'None'
                ELSE Category 
            END AS Category,
            [Transaction ID] AS txn_id,
            SUM([Net Sales]) AS cat_net_sales,
            SUM(COALESCE(CAST(REPLACE(REPLACE([Tax], '$', ''), ',', '') AS REAL), 0)) AS cat_tax,
            SUM([Gross Sales]) AS cat_gross,
            SUM(Qty) AS cat_qty
        FROM transactions
        GROUP BY date, Category, [Transaction ID]
    ),
    category_daily AS (
        SELECT
            date,
            Category,
            txn_id,
            SUM(ROUND(cat_net_sales + cat_tax, 2)) AS cat_total_with_tax,
            SUM(cat_net_sales) AS cat_net_sales,
            SUM(cat_tax) AS cat_tax,
            SUM(cat_gross) AS cat_gross,
            SUM(cat_qty) AS cat_qty
        FROM category_transactions
        GROUP BY date, Category, txn_id
    )
    SELECT
        date,
        Category,
        SUM(cat_total_with_tax) AS net_sales_with_tax,
        SUM(cat_net_sales) AS net_sales,
        SUM(cat_tax) AS total_tax,
        COUNT(DISTINCT txn_id) AS transactions,
        CASE 
            WHEN COUNT(DISTINCT txn_id) > 0 
            THEN SUM(cat_total_with_tax) * 1.0 / COUNT(DISTINCT txn_id)
            ELSE 0 
        END AS avg_txn,
        SUM(cat_gross) AS gross,
        SUM(cat_qty) AS qty
    FROM category_daily
    GROUP BY date, Category
    ORDER BY date, Category;
    """

    daily = pd.read_sql(daily_sql, db)
    category = pd.read_sql(category_sql, db)

    if not daily.empty:
        daily["date"] = pd.to_datetime(daily["date"])
        daily = daily.sort_values("date")

        # ç§»é™¤ç¼ºå¤±æ•°æ®çš„æ—¥æœŸ (8.18, 8.19, 8.20)
        missing_dates = ['2025-08-18', '2025-08-19', '2025-08-20']
        daily = daily[~daily["date"].isin(pd.to_datetime(missing_dates))]

        # è®¡ç®—æ»šåŠ¨å¹³å‡å€¼
        daily["3M_Avg_Rolling"] = daily["net_sales_with_tax"].rolling(window=90, min_periods=1, center=False).mean()
        daily["6M_Avg_Rolling"] = daily["net_sales_with_tax"].rolling(window=180, min_periods=1, center=False).mean()

    if not category.empty:
        category["date"] = pd.to_datetime(category["date"])
        category = category.sort_values(["Category", "date"])

        # ç§»é™¤ç¼ºå¤±æ•°æ®çš„æ—¥æœŸ - æ‰€æœ‰åˆ†ç±»éƒ½è¿‡æ»¤
        category = category[~category["date"].isin(pd.to_datetime(missing_dates))]

        # ä¸ºæ¯ä¸ªåˆ†ç±»è®¡ç®—æ»šåŠ¨å¹³å‡å€¼
        category_with_rolling = []
        for cat in category["Category"].unique():
            cat_data = category[category["Category"] == cat].copy()
            cat_data = cat_data.sort_values("date")
            cat_data["3M_Avg_Rolling"] = cat_data["net_sales_with_tax"].rolling(window=90, min_periods=1,
                                                                                center=False).mean()
            cat_data["6M_Avg_Rolling"] = cat_data["net_sales_with_tax"].rolling(window=180, min_periods=1,
                                                                                center=False).mean()
            category_with_rolling.append(cat_data)

        category = pd.concat(category_with_rolling, ignore_index=True)

    return daily, category


@st.cache_data(ttl=300, max_entries=50, show_spinner=False)
def prepare_chart_data_fast(daily, category_tx, inv_grouped, time_range, data_sel, cats_sel,
                            custom_dates_selected=False, t1=None, t2=None):
    """å¿«é€Ÿå‡†å¤‡å›¾è¡¨æ•°æ® - ä¼˜åŒ–ç¼“å­˜ç¨³å®šæ€§"""
    # ç¨³å®šç¼“å­˜é”® - å¯¹åˆ—è¡¨å‚æ•°æ’åºç¡®ä¿ç¼“å­˜é”®ä¸€è‡´
    time_range = sorted(time_range) if time_range else []
    data_sel = sorted(data_sel) if data_sel else []
    cats_sel = sorted(cats_sel) if cats_sel else []

    if not time_range or not data_sel or not cats_sel:
        return None

    # è·å–å½“å‰æ—¥æœŸ
    today = pd.Timestamp.today().normalize()

    # è®¡ç®—æ—¶é—´èŒƒå›´ç­›é€‰æ¡ä»¶
    start_of_week = today - pd.Timedelta(days=today.weekday())
    start_of_month = today.replace(day=1)
    start_of_year = today.replace(month=1, day=1)

    # åº”ç”¨æ—¶é—´èŒƒå›´ç­›é€‰åˆ°dailyæ•°æ®
    daily_filtered = daily.copy()
    grouped_tx = category_tx.copy()

    if "WTD" in time_range:
        daily_filtered = daily_filtered[daily_filtered["date"] >= start_of_week]
        grouped_tx = grouped_tx[grouped_tx["date"] >= start_of_week]
    if "MTD" in time_range:
        daily_filtered = daily_filtered[daily_filtered["date"] >= start_of_month]
        grouped_tx = grouped_tx[grouped_tx["date"] >= start_of_month]
    if "YTD" in time_range:
        daily_filtered = daily_filtered[daily_filtered["date"] >= start_of_year]
        grouped_tx = grouped_tx[grouped_tx["date"] >= start_of_year]
    if custom_dates_selected and t1 and t2:
        t1_ts = pd.to_datetime(t1)
        t2_ts = pd.to_datetime(t2)
        daily_filtered = daily_filtered[
            (daily_filtered["date"] >= t1_ts) & (daily_filtered["date"] <= t2_ts)]
        grouped_tx = grouped_tx[
            (grouped_tx["date"] >= t1_ts) & (grouped_tx["date"] <= t2_ts)]

    grouped_inv = inv_grouped.copy()
    # å¯¹åº“å­˜æ•°æ®åº”ç”¨ç›¸åŒçš„æ—¶é—´èŒƒå›´ç­›é€‰
    if not grouped_inv.empty:
        if "WTD" in time_range:
            grouped_inv = grouped_inv[grouped_inv["date"] >= start_of_week]
        if "MTD" in time_range:
            grouped_inv = grouped_inv[grouped_inv["date"] >= start_of_month]
        if "YTD" in time_range:
            grouped_inv = grouped_inv[grouped_inv["date"] >= start_of_year]
        if custom_dates_selected and t1 and t2:
            grouped_inv = grouped_inv[
                (grouped_inv["date"] >= pd.to_datetime(t1)) & (grouped_inv["date"] <= pd.to_datetime(t2))]

    # å®šä¹‰baråˆ†ç±»ï¼ˆè¿™5ä¸ªåˆ†ç±»ä½¿ç”¨ net_sales + tax è®¡ç®—ï¼‰
    bar_cats = {"Cafe Drinks", "Smoothie Bar", "Soups", "Sweet Treats", "Wraps & Salads", "Breakfast Bowls"}

    # ä¿®å¤ï¼šè¿‡æ»¤æ‰æ²¡æœ‰æ•°æ®çš„åˆ†ç±»ï¼Œé¿å…é‡å¤æ˜¾ç¤º
    small_cats = []
    for c in cats_sel:
        if c not in ("bar", "retail", "total"):
            small_cats.append(c)

    parts_tx = []

    if small_cats:
        # ä¸ºå°ç±»æ•°æ®æ·»åŠ æ»šåŠ¨å¹³å‡å€¼
        small_cats_data = grouped_tx[grouped_tx["Category"].isin(small_cats)].copy()

        # ä¿®å¤ï¼šæŒ‰æ—¥æœŸå’Œåˆ†ç±»é‡æ–°è®¡ç®— net_sales_with_tax
        for cat in small_cats:
            cat_mask = small_cats_data["Category"] == cat
            if cat not in bar_cats:  # ébaråˆ†ç±»ä½¿ç”¨ net_sales åˆ—
                # æŒ‰æ—¥æœŸåˆ†ç»„è®¡ç®—æ¯ä¸ªæ—¥æœŸçš„ net_sales æ€»å’Œ
                daily_net_sales = small_cats_data[cat_mask].groupby("date")["net_sales"].sum().reset_index()
                # ç»“æœå››èˆäº”å…¥ä¿ç•™æ•´æ•°
                daily_net_sales["net_sales_with_tax"] = daily_net_sales["net_sales"].apply(
                    lambda x: proper_round(x) if not pd.isna(x) else 0
                )

                # æ›´æ–°åŸå§‹æ•°æ®ä¸­çš„ net_sales_with_tax
                for _, row in daily_net_sales.iterrows():
                    date_mask = (small_cats_data["date"] == row["date"]) & (small_cats_data["Category"] == cat)
                    small_cats_data.loc[date_mask, "net_sales_with_tax"] = row["net_sales_with_tax"]

        parts_tx.append(small_cats_data)

    # å¤„ç†baråˆ†ç±» - é‡æ–°è®¡ç®—barçš„æ»šåŠ¨å¹³å‡ï¼ˆæ”¹ä¸ºä½¿ç”¨pure net saleï¼‰
    if "bar" in cats_sel:
        bar_tx = grouped_tx[grouped_tx["Category"].isin(bar_cats)].copy()
        if not bar_tx.empty:
            # æ”¹ä¸ºä½¿ç”¨ net_sales åˆ—ï¼ˆçº¯å‡€å‡€é”€å”®é¢ï¼‰
            bar_daily_agg = bar_tx.groupby("date").agg({
                "net_sales": "sum",
                "transactions": "sum",
                "qty": "sum",
                "3M_Avg_Rolling": "mean",
                "6M_Avg_Rolling": "mean"
            }).reset_index()

            # åŒæ—¶æŠŠæ–°åˆ—åç»Ÿä¸€ä¸º net_sales_with_taxï¼Œä»¥å…¼å®¹ä¸‹æ¸¸ç»˜å›¾é€»è¾‘
            bar_daily_agg["net_sales_with_tax"] = bar_daily_agg["net_sales"]

            # è®¡ç®—barçš„å¹³å‡äº¤æ˜“é¢
            bar_daily_agg["avg_txn"] = bar_daily_agg.apply(
                lambda x: x["net_sales"] / x["transactions"] if x["transactions"] > 0 else 0,
                axis=1
            )

            # ä¸ºbaræ•°æ®è®¡ç®—å‡†ç¡®çš„æ»šåŠ¨å¹³å‡ï¼ˆåŸºäºçº¯å‡€å‡€é”€å”®é¢ï¼‰
            bar_daily_agg["3M_Avg_Rolling"] = bar_daily_agg["net_sales"].rolling(window=90, min_periods=1,
                                                                                 center=False).mean()
            bar_daily_agg["6M_Avg_Rolling"] = bar_daily_agg["net_sales"].rolling(window=180, min_periods=1,
                                                                                 center=False).mean()

            bar_daily_agg["Category"] = "bar"
            parts_tx.append(bar_daily_agg)

    # å¤„ç†retailåˆ†ç±» = total - bar
    if "retail" in cats_sel:
        # è·å–æ¯æ—¥totalæ•°æ®
        total_daily = daily_filtered.copy()
        total_daily = total_daily.rename(columns={
            "net_sales_with_tax": "total_net_sales",
            "transactions": "total_transactions",
            "avg_txn": "total_avg_txn",
            "qty": "total_qty",
            "3M_Avg_Rolling": "total_3M_Avg",
            "6M_Avg_Rolling": "total_6M_Avg"
        })

        # è·å–æ¯æ—¥baræ•°æ®
        bar_daily = grouped_tx[grouped_tx["Category"].isin(bar_cats)].groupby("date").agg({
            "net_sales_with_tax": "sum",
            "transactions": "sum",
            "qty": "sum",
            "3M_Avg_Rolling": "mean",
            "6M_Avg_Rolling": "mean"
        }).reset_index()
        bar_daily = bar_daily.rename(columns={
            "net_sales_with_tax": "bar_net_sales",
            "transactions": "bar_transactions",
            "qty": "bar_qty",
            "3M_Avg_Rolling": "bar_3M_Avg",
            "6M_Avg_Rolling": "bar_6M_Avg"
        })

        # åˆå¹¶totalå’Œbaræ•°æ®
        retail_data = total_daily.merge(bar_daily, on="date", how="left")

        # è®¡ç®—retail = total - bar
        retail_data["net_sales_with_tax"] = retail_data["total_net_sales"] - retail_data["bar_net_sales"].fillna(0)
        retail_data["transactions"] = retail_data["total_transactions"] - retail_data["bar_transactions"].fillna(0)
        retail_data["qty"] = retail_data["total_qty"] - retail_data["bar_qty"].fillna(0)

        # è®¡ç®—retailçš„æ»šåŠ¨å¹³å‡å€¼
        retail_data["3M_Avg_Rolling"] = retail_data["net_sales_with_tax"].rolling(window=90, min_periods=1,
                                                                                  center=False).mean()
        retail_data["6M_Avg_Rolling"] = retail_data["net_sales_with_tax"].rolling(window=180, min_periods=1,
                                                                                  center=False).mean()

        # è®¡ç®—å¹³å‡äº¤æ˜“é¢
        retail_data["avg_txn"] = retail_data.apply(
            lambda x: x["net_sales_with_tax"] / x["transactions"] if x["transactions"] > 0 else 0,
            axis=1
        )

        # åªä¿ç•™éœ€è¦çš„åˆ—
        retail_tx = retail_data[
            ["date", "net_sales_with_tax", "transactions", "avg_txn", "qty", "3M_Avg_Rolling", "6M_Avg_Rolling"]].copy()
        retail_tx["Category"] = "retail"
        parts_tx.append(retail_tx)

    if "total" in cats_sel:
        total_tx = daily_filtered.copy()
        total_tx["Category"] = "total"
        parts_tx.append(total_tx)

    if not parts_tx:
        return None

    df_plot = pd.concat(parts_tx, ignore_index=True)

    data_map_extended = {
        "Daily Net Sales": "net_sales_with_tax",
        "Weekly Net Sales": "weekly_net_sales",
        "Daily Transactions": "transactions",
        "Avg Transaction": "avg_txn",
        "Items Sold": "qty",
        "Inventory Value": "inventory_value",
        "Profit (Amount)": "profit_amount",
        # ä¸ºæ¯ä¸ªæ•°æ®ç±»å‹æ·»åŠ å¯¹åº”çš„3Må’Œ6M Avg
        "Daily Net Sales 3M Avg": "3M_Avg_Rolling",
        "Daily Net Sales 6M Avg": "6M_Avg_Rolling",
        "Weekly Net Sales 3M Avg": "weekly_net_sales_3M_Avg",  # æ–°å¢è¿™ä¸€è¡Œ
        "Weekly Net Sales 6M Avg": "weekly_net_sales_6M_Avg",  # æ–°å¢è¿™ä¸€è¡Œ
        "Daily Transactions 3M Avg": "transactions_3M_Avg",
        "Daily Transactions 6M Avg": "transactions_6M_Avg",
        "Avg Transaction 3M Avg": "avg_txn_3M_Avg",
        "Avg Transaction 6M Avg": "avg_txn_6M_Avg",
        "Items Sold 3M Avg": "qty_3M_Avg",
        "Items Sold 6M Avg": "qty_6M_Avg",
    }

    # ä¸ºå…¶ä»–æ•°æ®ç±»å‹è®¡ç®—3Må’Œ6Mæ»šåŠ¨å¹³å‡å€¼
    if any("3M Avg" in data_type or "6M Avg" in data_type for data_type in data_sel):
        # ä¸ºtransactionsè®¡ç®—æ»šåŠ¨å¹³å‡
        df_plot["transactions_3M_Avg"] = df_plot.groupby("Category")["transactions"].transform(
            lambda x: x.rolling(window=90, min_periods=1, center=False).mean()
        )
        df_plot["transactions_6M_Avg"] = df_plot.groupby("Category")["transactions"].transform(
            lambda x: x.rolling(window=180, min_periods=1, center=False).mean()
        )

        # ä¸ºavg_txnè®¡ç®—æ»šåŠ¨å¹³å‡
        df_plot["avg_txn_3M_Avg"] = df_plot.groupby("Category")["avg_txn"].transform(
            lambda x: x.rolling(window=90, min_periods=1, center=False).mean()
        )
        df_plot["avg_txn_6M_Avg"] = df_plot.groupby("Category")["avg_txn"].transform(
            lambda x: x.rolling(window=180, min_periods=1, center=False).mean()
        )

        # ä¸ºqtyè®¡ç®—æ»šåŠ¨å¹³å‡
        df_plot["qty_3M_Avg"] = df_plot.groupby("Category")["qty"].transform(
            lambda x: x.rolling(window=90, min_periods=1, center=False).mean()
        )
        df_plot["qty_6M_Avg"] = df_plot.groupby("Category")["qty"].transform(
            lambda x: x.rolling(window=180, min_periods=1, center=False).mean()
        )

    # å¤„ç†åº“å­˜æ•°æ®
    if any(data in ["Inventory Value", "Profit (Amount)"] for data in data_sel):
        if not grouped_inv.empty:
            grouped_inv_plot = grouped_inv.copy()
            grouped_inv_plot = grouped_inv_plot.rename(columns={
                "Inventory Value": "inventory_value",
                "Profit": "profit_amount"
            })
            # æ·»åŠ ç¼ºå¤±çš„åˆ—
            for col in ["net_sales_with_tax", "transactions", "avg_txn", "qty", "3M_Avg_Rolling", "6M_Avg_Rolling"]:
                grouped_inv_plot[col] = 0

            # åˆå¹¶åº“å­˜æ•°æ®
            if small_cats:
                inv_small = grouped_inv_plot[grouped_inv_plot["Category"].isin(small_cats)]
                df_plot = pd.concat([df_plot, inv_small], ignore_index=True)

            if "bar" in cats_sel:
                bar_inv = grouped_inv_plot[grouped_inv_plot["Category"].isin(bar_cats)].copy()
                if not bar_inv.empty:
                    bar_inv["Category"] = "bar"
                    df_plot = pd.concat([df_plot, bar_inv], ignore_index=True)

            if "retail" in cats_sel:
                retail_inv = grouped_inv_plot[grouped_inv_plot["Category"] == "Retail"].copy()
                if not retail_inv.empty:
                    retail_inv["Category"] = "retail"
                    df_plot = pd.concat([df_plot, retail_inv], ignore_index=True)

            if "total" in cats_sel:
                total_inv = grouped_inv_plot.copy()
                total_inv_sum = total_inv.groupby("date").agg({
                    "inventory_value": "sum",
                    "profit_amount": "sum"
                }).reset_index()
                total_inv_sum["Category"] = "total"
                for col in ["net_sales_with_tax", "transactions", "avg_txn", "qty", "3M_Avg_Rolling", "6M_Avg_Rolling"]:
                    total_inv_sum[col] = 0
                df_plot = pd.concat([df_plot, total_inv_sum], ignore_index=True)

    # ç¡®ä¿æ‰€æœ‰éœ€è¦çš„åˆ—éƒ½å­˜åœ¨
    for col_name in data_map_extended.values():
        if col_name not in df_plot.columns:
            df_plot[col_name] = 0

    # æ·»åŠ åº“å­˜æ•°æ®åˆ—
    if "inventory_value" not in df_plot.columns:
        df_plot["inventory_value"] = 0
    if "profit_amount" not in df_plot.columns:
        df_plot["profit_amount"] = 0

    # === æ–°å¢ï¼šWeekly Net Sales è®¡ç®— ===
    if "Weekly Net Sales" in data_sel or any("Weekly Net Sales" in dt for dt in data_sel):
        # åˆ›å»ºå‘¨èšåˆæ•°æ®
        weekly_base_data = []

        # ä¸ºæ¯ä¸ªåˆ†ç±»å•ç‹¬å¤„ç†å‘¨æ•°æ®
        for category in df_plot['Category'].unique():
            cat_data = df_plot[df_plot['Category'] == category].copy()

            # === ä¿®å¤ï¼šä½¿ç”¨ %Y-%W æ ¼å¼ï¼Œä»¥å‘¨ä¸€ä½œä¸ºä¸€å‘¨çš„ç¬¬ä¸€å¤© ===
            cat_data['year_week'] = cat_data['date'].dt.strftime('%Y-%W')

            # æŒ‰å‘¨åˆ†ç»„èšåˆ
            weekly_agg = cat_data.groupby('year_week').agg({
                'net_sales_with_tax': 'sum',
                'transactions': 'sum',
                'avg_txn': 'mean',
                'qty': 'sum'
            }).reset_index()

            # åªä¿ç•™æœ‰å®é™…é”€å”®æ•°æ®çš„å‘¨
            weekly_agg = weekly_agg[weekly_agg['net_sales_with_tax'] > 0]

            if not weekly_agg.empty:
                # === ä¿®å¤ï¼šä½¿ç”¨æ­£ç¡®çš„å‘¨è®¡ç®—ï¼Œä»¥å‘¨ä¸€ä½œä¸ºä¸€å‘¨çš„ç¬¬ä¸€å¤© ===
                weekly_agg['date'] = pd.to_datetime(weekly_agg['year_week'] + '-1', format='%Y-%W-%w')
                weekly_agg['Category'] = category

                # === ä¿®å¤ï¼šæ­£ç¡®çš„å‘¨æ»šåŠ¨å¹³å‡å€¼è®¡ç®— ===
                # æŒ‰æ—¥æœŸæ’åº
                weekly_agg = weekly_agg.sort_values('date')

                # è®¡ç®—å‘¨æ»šåŠ¨å¹³å‡å€¼ï¼ˆ13å‘¨å’Œ26å‘¨ï¼Œå¯¹åº”3ä¸ªæœˆå’Œ6ä¸ªæœˆï¼‰
                weekly_agg['weekly_net_sales_3M_Avg'] = weekly_agg['net_sales_with_tax'].rolling(
                    window=13, min_periods=1, center=False
                ).mean()
                weekly_agg['weekly_net_sales_6M_Avg'] = weekly_agg['net_sales_with_tax'].rolling(
                    window=26, min_periods=1, center=False
                ).mean()

                # é‡å‘½ååˆ—ä»¥åŒ¹é…æ•°æ®æ˜ å°„
                weekly_agg = weekly_agg.rename(columns={
                    'net_sales_with_tax': 'weekly_net_sales'
                })

                # === å…³é”®ä¿®å¤ï¼šç¡®ä¿æ‰€æœ‰éœ€è¦çš„åˆ—éƒ½å­˜åœ¨ ===
                # æ·»åŠ å…¶ä»–å¿…è¦åˆ—
                required_columns = ['inventory_value', 'profit_amount',
                                    'transactions_3M_Avg', 'transactions_6M_Avg',
                                    'avg_txn_3M_Avg', 'avg_txn_6M_Avg',
                                    'qty_3M_Avg', 'qty_6M_Avg',
                                    '3M_Avg_Rolling', '6M_Avg_Rolling']

                for col in required_columns:
                    weekly_agg[col] = 0

                weekly_base_data.append(weekly_agg)

        if weekly_base_data:
            # åˆå¹¶æ‰€æœ‰åˆ†ç±»çš„å‘¨æ•°æ®
            weekly_combined = pd.concat(weekly_base_data, ignore_index=True)

            # åªä¿ç•™éœ€è¦çš„åˆ—
            keep_columns = ['date', 'Category', 'weekly_net_sales', 'weekly_net_sales_3M_Avg',
                            'weekly_net_sales_6M_Avg', 'transactions', 'avg_txn', 'qty',
                            '3M_Avg_Rolling', '6M_Avg_Rolling', 'inventory_value', 'profit_amount',
                            'transactions_3M_Avg', 'transactions_6M_Avg', 'avg_txn_3M_Avg',
                            'avg_txn_6M_Avg', 'qty_3M_Avg', 'qty_6M_Avg']

            # ç¡®ä¿æ‰€æœ‰åˆ—éƒ½å­˜åœ¨
            for col in keep_columns:
                if col not in weekly_combined.columns:
                    weekly_combined[col] = 0

            weekly_combined = weekly_combined[keep_columns]

            # === å…³é”®ä¿®æ”¹ï¼šå°†å‘¨æ•°æ®æ·»åŠ åˆ°ä¸»æ•°æ®æ¡†ï¼Œè€Œä¸æ˜¯æ›¿æ¢ ===
            # å°†å‘¨æ•°æ®åˆå¹¶åˆ°ä¸»æ•°æ®æ¡†ä¸­ï¼ˆæ·»åŠ è€Œä¸æ˜¯æ›¿æ¢ï¼‰
            df_plot = pd.concat([df_plot, weekly_combined], ignore_index=True)

            # ç§»é™¤ä¸´æ—¶çš„ year_week åˆ—ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if 'year_week' in df_plot.columns:
                df_plot = df_plot.drop('year_week', axis=1)

    # === åœ¨è¿™é‡Œæ·»åŠ è°ƒè¯•ä»£ç  ===
    print("=== DEBUG INFO ===")
    print("Available columns in df_plot:", sorted(df_plot.columns.tolist()))
    print("Data types selected:", data_sel)
    print("--- Column existence check ---")
    for data_type in data_sel:
        col_name = data_map_extended.get(data_type)
        exists = col_name in df_plot.columns if col_name else False
        print(f"Data type: {data_type:25} | Column: {col_name:30} | Exists: {exists}")
    print("=== END DEBUG ===")

    # === æ–°å¢ï¼šWeekly Net Sales åˆ—æ£€æŸ¥ ===
    print("=== DEBUG: Weekly Net Sales Columns ===")
    print("weekly_net_sales in columns:", 'weekly_net_sales' in df_plot.columns)
    print("weekly_net_sales_3M_Avg in columns:", 'weekly_net_sales_3M_Avg' in df_plot.columns)
    print("weekly_net_sales_6M_Avg in columns:", 'weekly_net_sales_6M_Avg' in df_plot.columns)

    if 'weekly_net_sales' in df_plot.columns:
        weekly_data_exists = (df_plot['weekly_net_sales'] > 0).any()
        print("Weekly data exists:", weekly_data_exists)
        if weekly_data_exists:
            sample_weekly = df_plot[df_plot['weekly_net_sales'] > 0].head(3)
            print("Sample weekly data:")
            print(sample_weekly[
                      ['date', 'Category', 'weekly_net_sales', 'weekly_net_sales_3M_Avg', 'weekly_net_sales_6M_Avg']])

    melted_dfs = []
    for data_type in data_sel:
        col_name = data_map_extended.get(data_type)
        if col_name and col_name in df_plot.columns:
            temp_df = df_plot[["date", "Category", col_name]].copy()
            temp_df = temp_df.rename(columns={col_name: "value"})
            temp_df["data_type"] = data_type

            # === ä¿®æ”¹ï¼šå¯¹ Daily Net Sales å’Œ Weekly Net Sales è¿›è¡Œå››èˆäº”å…¥å–æ•´ ===
            if data_type in ["Daily Net Sales", "Weekly Net Sales"]:
                temp_df["value"] = temp_df["value"].apply(lambda x: proper_round(x) if not pd.isna(x) else 0)

            # === å…³é”®ä¿®æ”¹ï¼šå¯¹äº Weekly Net Sales åŠå…¶å¹³å‡å€¼ï¼Œç§»é™¤å€¼ä¸º0çš„æ•°æ®ç‚¹ ===
            if data_type in ["Weekly Net Sales", "Weekly Net Sales 3M Avg", "Weekly Net Sales 6M Avg"]:
                temp_df = temp_df[temp_df["value"] > 0]

            # æ”¾å®½è¿‡æ»¤æ¡ä»¶
            temp_df = temp_df[temp_df["value"].notna()]
            if not temp_df.empty:
                melted_dfs.append(temp_df)
                
    if melted_dfs:
        combined_df = pd.concat(melted_dfs, ignore_index=True)
        combined_df["series"] = combined_df["Category"] + " - " + combined_df["data_type"]

        # ç¡®ä¿æœ€ç»ˆæ•°æ®ä¸­å®Œå…¨ç§»é™¤ç¼ºå¤±æ—¥æœŸçš„æ•°æ®ç‚¹
        missing_dates = ['2025-08-18', '2025-08-19', '2025-08-20']
        combined_df = combined_df[~combined_df["date"].isin(pd.to_datetime(missing_dates))]

        # ä¿®å¤ï¼šç¡®ä¿æ—¥æœŸæŒ‰æ­£ç¡®é¡ºåºæ’åº
        combined_df = combined_df.sort_values("date")

        return combined_df

    return None


def show_high_level(tx: pd.DataFrame, mem: pd.DataFrame, inv: pd.DataFrame):
    # === å…¨å±€æ ·å¼ï¼šæ¶ˆé™¤é¡¶éƒ¨æ ‡é¢˜é—´è· ===
    st.markdown("""
    <style>
    /* å»æ‰ Vie Manly Dashboard ä¸ High Level Report ä¹‹é—´çš„ç©ºç™½ */
    div.block-container h1, 
    div.block-container h2, 
    div.block-container h3, 
    div.block-container p {
        margin-top: 0rem !important;
        margin-bottom: 0rem !important;
        padding-top: 0rem !important;
        padding-bottom: 0rem !important;
    }

    /* æ›´å¼ºåŠ›åœ°å‹ç¼© Streamlit è‡ªåŠ¨æ’å…¥çš„ vertical space */
    div.block-container > div {
        margin-top: 0rem !important;
        margin-bottom: 0rem !important;
        padding-top: 0rem !important;
        padding-bottom: 0rem !important;
    }

    /* æ¶ˆé™¤æ ‡é¢˜å’Œé€‰æ‹©æ¡†ä¹‹é—´ç©ºéš™ */
    div[data-testid="stVerticalBlock"] > div {
        margin-top: 0rem !important;
        margin-bottom: 0rem !important;
    }
    </style>
    """, unsafe_allow_html=True)

    # === ä¿ç•™æ ‡é¢˜ ===
    st.markdown("<h2 style='font-size:24px; font-weight:700;'>ğŸ“Š High Level Report</h2>", unsafe_allow_html=True)

    # åœ¨ç°æœ‰çš„æ ·å¼åé¢æ·»åŠ ï¼š
    st.markdown("""
    <style>
    /* è®©å¤šé€‰æ¡†åˆ—æ›´ç´§å‡‘ */
    div[data-testid="column"] {
        padding: 0 8px !important;
    }
    div[data-baseweb="select"] {
        min-width: 12ch !important;
        max-width: 20ch !important;
    }
    </style>
    """, unsafe_allow_html=True)

    # é¢„åŠ è½½æ‰€æœ‰æ•°æ®
    with st.spinner("Loading data..."):
        daily, category_tx = preload_all_data()
        inv_grouped, inv_latest_date = _prepare_inventory_grouped(inv)

    # åˆå§‹åŒ–åˆ†ç±»é€‰æ‹©çš„ session state
    if "hl_cats" not in st.session_state:
        st.session_state["hl_cats"] = []

    if daily.empty:
        st.warning("No transaction data available. Please upload data first.")
        return

    # === ç‰¹å®šæ—¥æœŸé€‰æ‹© ===
    # æ”¹ä¸ºä¸¤åˆ—å¸ƒå±€ï¼šæ—¶é—´èŒƒå›´é€‰æ‹© + æ—¥æœŸé€‰æ‹©
    col_time_range, col_date, _ = st.columns([1, 1, 5])

    # === æ·»åŠ ç©ºç™½è¡Œç¡®ä¿æ°´å¹³å¯¹é½ ===
    #st.markdown("<div style='margin-top: 0.5rem;'></div>", unsafe_allow_html=True)

    st.markdown("""
    <style>

    /* è®©å¤šé€‰æ¡†åˆ—æ›´ç´§å‡‘ */
    div[data-testid="column"] {
        padding: 0 8px !important;
    }

    /* ç²¾ç¡®æ§åˆ¶ summary_time_range ä¸‹æ‹‰æ¡†å®½åº¦ */
    div[data-testid*="summary_time_range"] > div[data-baseweb="select"] {
        width: 14ch !important;
        min-width: 14ch !important;
        max-width: 14ch !important;
    }

    /* æ—¥æœŸé€‰æ‹©æ¡†å®¹å™¨ - ç²¾ç¡®å®½åº¦ */
    div[data-testid*="stSelectbox"] {
        width: 18ch !important;
        min-width: 18ch !important;
        max-width: 18ch !important;
        display: inline-block !important;
    }

    /* æ—¥æœŸé€‰æ‹©æ¡†æ ‡ç­¾ */
    div[data-testid*="stSelectbox"] label {
        white-space: nowrap !important;
        font-size: 0.9rem !important;
        width: 100% !important;
    }

    /* ä¸‹æ‹‰èœå• */
    div[data-testid*="stSelectbox"] [data-baseweb="select"] {
        width: 18ch !important;
        min-width: 18ch !important;
        max-width: 18ch !important;
    }

    /* ä¸‹æ‹‰é€‰é¡¹å®¹å™¨ */
    div[role="listbox"] {
        min-width: 18ch !important;
        max-width: 18ch !important;
    }

    /* éšè—å¤šä½™çš„ä¸‹æ‹‰ç®­å¤´ç©ºé—´ */
    div[data-testid*="stSelectbox"] [data-baseweb="select"] > div {
        padding-right: 0 !important;
    }
    </style>
    """, unsafe_allow_html=True)

    with col_time_range:
        # === ç§»é™¤ç©ºç™½æ ‡ç­¾ï¼Œç°åœ¨ç”¨CSSæ§åˆ¶ ===
        summary_time_options = ["Daily", "WTD", "MTD", "YTD", "Custom dates"]
        summary_time_range = st.selectbox(
            "Choose time range",
            summary_time_options,
            key="summary_time_range"
        )

    with col_date:

        # åªæœ‰å½“é€‰æ‹©Dailyæ—¶æ‰æ˜¾ç¤ºæ—¥æœŸé€‰æ‹©æ¡†
        if summary_time_range == "Daily":
            available_dates = sorted(daily["date"].dt.date.unique(), reverse=True)
            available_dates_formatted = [date.strftime('%d/%m/%Y') for date in available_dates]

            date_width = 18
            selectbox_width = date_width + 1


            selected_date_formatted = st.selectbox("Choose date", available_dates_formatted)

            # å°†é€‰æ‹©çš„æ—¥æœŸè½¬æ¢å›æ—¥æœŸå¯¹è±¡
            selected_date = pd.to_datetime(selected_date_formatted, format='%d/%m/%Y').date()
        else:
            # å¯¹äºéDailyé€‰é¡¹ï¼Œè®¾ç½®ä¸€ä¸ªé»˜è®¤æ—¥æœŸï¼ˆä½¿ç”¨æœ€æ–°æ—¥æœŸï¼‰
            selected_date = daily["date"].max().date()
            selected_date_formatted = selected_date.strftime('%d/%m/%Y')

    # === è‡ªå®šä¹‰æ—¥æœŸèŒƒå›´é€‰æ‹©ï¼ˆä»…å½“é€‰æ‹©Custom datesæ—¶æ˜¾ç¤ºï¼‰ ===
    summary_custom_dates_selected = False
    summary_t1 = None
    summary_t2 = None

    if summary_time_range == "Custom dates":
        summary_custom_dates_selected = True
        st.markdown("<h4 style='font-size:16px; font-weight:700;'>ğŸ“… Custom Date Range for Summary</h4>",
                    unsafe_allow_html=True)

        col_from, col_to, _ = st.columns([1, 1, 5])

        with col_from:
            summary_t1 = st.date_input(
                "From",
                value=pd.Timestamp.today().normalize() - pd.Timedelta(days=7),
                key="summary_date_from",
                format="DD/MM/YYYY"
            )

        with col_to:
            summary_t2 = st.date_input(
                "To",
                value=pd.Timestamp.today().normalize(),
                key="summary_date_to",
                format="DD/MM/YYYY"
            )

    # === æ ¹æ®æ—¶é—´èŒƒå›´ç­›é€‰æ•°æ® ===
    # === æ ¹æ®æ—¶é—´èŒƒå›´ç­›é€‰æ•°æ® ===
    def filter_data_by_time_range(data, time_range, selected_date, custom_dates_selected=False, t1=None, t2=None):
        """æ ¹æ®æ—¶é—´èŒƒå›´ç­›é€‰æ•°æ®"""
        if data.empty:
            return data

        data_filtered = data.copy()

        # è·å–å½“å‰æ—¥æœŸ
        today = pd.Timestamp.today().normalize()

        # è®¡ç®—æ—¶é—´èŒƒå›´ç­›é€‰æ¡ä»¶
        start_of_week = today - pd.Timedelta(days=today.weekday())
        start_of_month = today.replace(day=1)
        start_of_year = today.replace(month=1, day=1)

        # æ£€æŸ¥æ•°æ®æ¡†æ˜¯å¦æœ‰dateåˆ—ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨Datetimeåˆ—
        if 'date' in data_filtered.columns:
            date_col = 'date'
        elif 'Datetime' in data_filtered.columns:
            date_col = 'Datetime'
            # ç¡®ä¿Datetimeåˆ—æ˜¯datetimeç±»å‹
            data_filtered[date_col] = pd.to_datetime(data_filtered[date_col])
        else:
            # å¦‚æœæ²¡æœ‰æ—¥æœŸåˆ—ï¼Œè¿”å›åŸå§‹æ•°æ®
            return data_filtered

        if time_range == "WTD":
            data_filtered = data_filtered[data_filtered[date_col] >= start_of_week]
        elif time_range == "MTD":
            data_filtered = data_filtered[data_filtered[date_col] >= start_of_month]
        elif time_range == "YTD":
            data_filtered = data_filtered[data_filtered[date_col] >= start_of_year]
        elif time_range == "Daily":
            data_filtered = data_filtered[data_filtered[date_col].dt.date == selected_date]
        elif time_range == "Custom dates" and custom_dates_selected and t1 and t2:
            t1_ts = pd.to_datetime(t1)
            t2_ts = pd.to_datetime(t2)
            data_filtered = data_filtered[
                (data_filtered[date_col] >= t1_ts) & (data_filtered[date_col] <= t2_ts)
                ]

        return data_filtered

    # ç­›é€‰dailyæ•°æ®
    df_selected_date = filter_data_by_time_range(
        daily, summary_time_range, selected_date,
        summary_custom_dates_selected, summary_t1, summary_t2
    )

    # è½¬æ¢ selected_date ä¸º Timestamp ç”¨äºæ¯”è¾ƒ
    selected_date_ts = pd.Timestamp(selected_date)

    # === è®¡ç®—å®¢æˆ·æ•°é‡ ===
    def calculate_customer_count(tx_df, time_range, selected_date, custom_dates_selected=False, t1=None, t2=None):
        if tx_df is None or tx_df.empty:
            return 0
        if 'Datetime' not in tx_df.columns:
            return 0

        # æ ¹æ®æ—¶é—´èŒƒå›´ç­›é€‰äº¤æ˜“æ•°æ®
        tx_df_filtered = filter_data_by_time_range(
            tx_df, time_range, selected_date, custom_dates_selected, t1, t2
        )

        if tx_df_filtered.empty:
            return 0

        if 'Card Brand' not in tx_df_filtered.columns or 'PAN Suffix' not in tx_df_filtered.columns:
            return 0

        filtered_tx = tx_df_filtered.dropna(subset=['Card Brand', 'PAN Suffix'])
        if filtered_tx.empty:
            return 0

        filtered_tx['Card Brand'] = filtered_tx['Card Brand'].str.title()
        filtered_tx['PAN Suffix'] = filtered_tx['PAN Suffix'].astype(str).str.split('.').str[0]
        unique_customers = filtered_tx[['Card Brand', 'PAN Suffix']].drop_duplicates()

        return len(unique_customers)
    # === è®¡ç®—barå’Œretailçš„ç‰¹å®šæ—¥æœŸæ•°æ® ===
    def calculate_bar_retail_data(category_tx, time_range, selected_date, daily_data, custom_dates_selected=False,
                                  t1=None, t2=None):
        """è®¡ç®—barå’Œretailåœ¨é€‰å®šæ—¶é—´èŒƒå›´çš„æ•°æ®"""

        # baråˆ†ç±»å®šä¹‰
        bar_cats = {"Cafe Drinks", "Smoothie Bar", "Soups", "Sweet Treats", "Wraps & Salads", "Breakfast Bowls"}


        # æ ¹æ®æ—¶é—´èŒƒå›´ç­›é€‰åˆ†ç±»æ•°æ®
        category_filtered = filter_data_by_time_range(
            category_tx, time_range, selected_date, custom_dates_selected, t1, t2
        )

        # === è®¡ç®—baræ•°æ® ===
        bar_data = category_filtered[category_filtered["Category"].isin(bar_cats)].copy()
        bar_net_sales_raw = bar_data["net_sales"].sum()
        bar_net_sales = proper_round(bar_net_sales_raw)
        bar_transactions = bar_data["transactions"].sum()
        bar_avg_txn = bar_net_sales_raw / bar_transactions if bar_transactions > 0 else 0
        bar_qty = bar_data["qty"].sum()

        # === ä¿®æ­£ç‰ˆï¼šä½¿ç”¨ category_tx è®¡ç®—è¿‘90/180å¤© bar æ€»é”€å”®å¹³å‡ ===
        bar_all = category_tx[category_tx["Category"].isin(bar_cats)].copy()
        bar_all = bar_all.sort_values("date")

        selected_date_ts = pd.Timestamp(selected_date)
        bar_recent_3m = bar_all[bar_all["date"] >= (selected_date_ts - pd.Timedelta(days=90))]
        bar_recent_6m = bar_all[bar_all["date"] >= (selected_date_ts - pd.Timedelta(days=180))]

        bar_3m_avg = proper_round(bar_recent_3m["net_sales"].sum() / 90) if not bar_recent_3m.empty else 0
        bar_6m_avg = proper_round(bar_recent_6m["net_sales"].sum() / 180) if not bar_recent_6m.empty else 0

        # === è®¡ç®—retailæ•°æ® ===
        retail_data = category_filtered[~category_filtered["Category"].isin(bar_cats)].copy()
        # Retail = sum all non-bar net_sales then round (çº¯å‡€å‡€é”€å”®é¢)
        retail_net_sales_raw = pd.to_numeric(retail_data["net_sales"], errors="coerce").sum()
        retail_net_sales = proper_round(retail_net_sales_raw)

        retail_transactions = retail_data["transactions"].sum()
        retail_avg_txn = retail_net_sales_raw / retail_transactions if retail_transactions > 0 else 0
        retail_qty = retail_data["qty"].sum()

        retail_all = category_tx[~category_tx["Category"].isin(bar_cats)].copy()
        retail_all = retail_all.sort_values("date")

        retail_recent_3m = retail_all[retail_all["date"] >= (selected_date_ts - pd.Timedelta(days=90))]
        retail_recent_6m = retail_all[retail_all["date"] >= (selected_date_ts - pd.Timedelta(days=180))]

        retail_3m_avg = proper_round(retail_recent_3m["net_sales"].sum() / 90) if not retail_recent_3m.empty else 0
        retail_6m_avg = proper_round(retail_recent_6m["net_sales"].sum() / 180) if not retail_recent_6m.empty else 0

        # total åº”è¯¥æ˜¯æ‰€æœ‰å•ä¸€ç±»çš„net salesæ±‚å’Œåå››èˆäº”å…¥
        # å…ˆè·å–æ‰€æœ‰åˆ†ç±»æ•°æ®ï¼ˆåŒ…æ‹¬barå’Œébaråˆ†ç±»ï¼‰
        all_categories_data = category_filtered.copy()
        # Total = sum all category net_sales then round (çº¯å‡€å‡€é”€å”®é¢)
        total_net_sales_raw = pd.to_numeric(all_categories_data["net_sales"], errors="coerce").sum()
        total_net_sales = proper_round(total_net_sales_raw)

        total_transactions = all_categories_data["transactions"].sum()
        total_qty = all_categories_data["qty"].sum()

        # === å®¢æˆ·æ•°ä¿æŒæŒ‰äº¤æ˜“æ¯”ä¾‹åˆ†é… ===
        total_customers = calculate_customer_count(tx, time_range, selected_date, custom_dates_selected, t1, t2)
        bar_customers = int(total_customers * (bar_transactions / total_transactions)) if total_transactions > 0 else 0
        retail_customers = total_customers - bar_customers

        return {
            "bar": {
                "Daily Net Sales": bar_net_sales,
                "Daily Transactions": bar_transactions,
                "# of Customers": bar_customers,
                "Avg Transaction": bar_avg_txn,
                "3M Avg": bar_3m_avg,
                "6M Avg": bar_6m_avg,
                "Items Sold": bar_qty
            },
            "retail": {
                "Daily Net Sales": retail_net_sales,
                "Daily Transactions": retail_transactions,
                "# of Customers": retail_customers,
                "Avg Transaction": retail_avg_txn,
                "3M Avg": retail_3m_avg,
                "6M Avg": retail_6m_avg,
                "Items Sold": retail_qty
            },
            "total": {
                "Daily Net Sales": total_net_sales,
                "Daily Transactions": total_transactions,
                "# of Customers": total_customers,
                "Avg Transaction": total_net_sales / total_transactions if total_transactions > 0 else 0,
                "3M Avg": bar_3m_avg + retail_3m_avg,
                "6M Avg": bar_6m_avg + retail_6m_avg,
                "Items Sold": total_qty
            }
        }

    # === KPIï¼ˆäº¤æ˜“ï¼Œå£å¾„æŒ‰å°ç¥¨ï¼‰ ===
    kpis_main = {
        "Daily Net Sales": proper_round(df_selected_date["net_sales_with_tax"].sum()),
        "Daily Transactions": df_selected_date["transactions"].sum(),
        "# of Customers": calculate_customer_count(tx, summary_time_range, selected_date, summary_custom_dates_selected, summary_t1, summary_t2),
        "Avg Transaction": df_selected_date["avg_txn"].mean(),
        "3M Avg": proper_round(daily["3M_Avg_Rolling"].iloc[-1]),
        "6M Avg": proper_round(daily["6M_Avg_Rolling"].iloc[-1]),
        "Items Sold": df_selected_date["qty"].sum(),
    }

    # === KPIï¼ˆåº“å­˜æ´¾ç”Ÿï¼Œcatalogue-onlyï¼‰ ===
    inv_value_latest = 0.0
    profit_latest = 0.0
    if inv_grouped is not None and not inv_grouped.empty and inv_latest_date is not None:
        sub = inv_grouped[inv_grouped["date"] == inv_latest_date]
        inv_value_latest = float(pd.to_numeric(sub["Inventory Value"], errors="coerce").sum())
        profit_latest = float(pd.to_numeric(sub["Profit"], errors="coerce").sum())

    # è®¡ç®—barå’Œretailæ•°æ®
    bar_retail_data = calculate_bar_retail_data(
        category_tx, summary_time_range, selected_date, daily,
        summary_custom_dates_selected, summary_t1, summary_t2
    )

    # æ˜¾ç¤ºé€‰å®šæ—¥æœŸï¼ˆå­—ä½“åŠ å¤§ï¼‰
    st.markdown(
        f"<h3 style='font-size:18px; font-weight:700;'>Selected Date: {selected_date.strftime('%d/%m/%Y')}</h3>",
        unsafe_allow_html=True)

    # ===== ç»„è£…ä¸‰è¡Œæ•°æ® =====
    total_row = [
        f"${proper_round(bar_retail_data['total']['Daily Net Sales']):,}",
        f"{proper_round(bar_retail_data['total']['Daily Transactions']):,}",
        f"{proper_round(bar_retail_data['total']['# of Customers']):,}",
        f"${bar_retail_data['total']['Avg Transaction']:.2f}",
        f"${proper_round(bar_retail_data['total']['3M Avg']):,}",
        f"${proper_round(bar_retail_data['total']['6M Avg']):,}",
        f"{proper_round(bar_retail_data['total']['Items Sold']):,}",
        f"${proper_round(inv_value_latest):,} <br><span style='font-size:10px; color:#666;'>as of {pd.to_datetime(inv_latest_date).strftime('%d/%m/%Y') if inv_latest_date else '-'}</span>"
    ]

    bar_row = [
        f"${proper_round(bar_retail_data['bar']['Daily Net Sales']):,}",
        f"{proper_round(bar_retail_data['bar']['Daily Transactions']):,}",
        f"{proper_round(bar_retail_data['bar']['# of Customers']):,}",
        f"${bar_retail_data['bar']['Avg Transaction']:.2f}",
        f"${proper_round(bar_retail_data['bar']['3M Avg']):,}",
        f"${proper_round(bar_retail_data['bar']['6M Avg']):,}",
        f"{proper_round(bar_retail_data['bar']['Items Sold']):,}",
        "-"
    ]

    retail_row = [
        f"${proper_round(bar_retail_data['retail']['Daily Net Sales']):,}",
        f"{proper_round(bar_retail_data['retail']['Daily Transactions']):,}",
        f"{proper_round(bar_retail_data['retail']['# of Customers']):,}",
        f"${bar_retail_data['retail']['Avg Transaction']:.2f}",
        f"${proper_round(bar_retail_data['retail']['3M Avg']):,}",
        f"${proper_round(bar_retail_data['retail']['6M Avg']):,}",
        f"{proper_round(bar_retail_data['retail']['Items Sold']):,}",
        "-"
    ]

    # ===== æ¸²æŸ“æˆ HTML è¡¨æ ¼ =====
    # === æ–°å¢ï¼šSummary Tableåˆ—å®½é…ç½® ===
    column_widths = {
        "label": "110px",
        "Percentage": "80px",
        "Daily Net Sales": "130px",
        "Daily Transactions": "140px",
        "# of Customers": "140px",
        "Avg Transaction": "125px",
        "3M Avg": "115px",
        "6M Avg": "115px",
        "Items Sold": "115px",
        "Inventory Value": "140px"
    }

    # åˆ›å»ºæ•°æ®æ¡†
    summary_data = {
        '': ['Bar', 'Retail', 'Total'],
        'Percentage': [
            f"{(bar_retail_data['bar']['Daily Net Sales'] / kpis_main['Daily Net Sales'] * 100):.2f}%" if kpis_main[
                                                                                                              'Daily Net Sales'] > 0 else "0.00%",
            f"{(bar_retail_data['retail']['Daily Net Sales'] / kpis_main['Daily Net Sales'] * 100):.2f}%" if kpis_main[
                                                                                                                 'Daily Net Sales'] > 0 else "0.00%",
            "-"
        ],
        'Daily Net Sales': [
            f"${proper_round(bar_retail_data['bar']['Daily Net Sales']):,}",
            f"${proper_round(bar_retail_data['retail']['Daily Net Sales']):,}",
            f"${proper_round(bar_retail_data['bar']['Daily Net Sales'] + bar_retail_data['retail']['Daily Net Sales']):,}"
        ],
        'Daily Transactions': [
            f"{proper_round(bar_retail_data['bar']['Daily Transactions']):,}",
            f"{proper_round(bar_retail_data['retail']['Daily Transactions']):,}",
            f"{proper_round(kpis_main['Daily Transactions']):,}"
        ],
        '# of Customers': [
            f"{proper_round(bar_retail_data['bar']['# of Customers']):,}",
            f"{proper_round(bar_retail_data['retail']['# of Customers']):,}",
            f"{proper_round(kpis_main['# of Customers']):,}"
        ],
        'Avg Transaction': [
            f"${bar_retail_data['bar']['Avg Transaction']:.2f}",
            f"${bar_retail_data['retail']['Avg Transaction']:.2f}",
            f"${kpis_main['Avg Transaction']:.2f}"
        ],
        '3M Avg': [
            f"${proper_round(bar_retail_data['bar']['3M Avg']):,}",
            f"${proper_round(bar_retail_data['retail']['3M Avg']):,}",
            f"${proper_round(kpis_main['3M Avg']):,}"
        ],
        '6M Avg': [
            f"${proper_round(bar_retail_data['bar']['6M Avg']):,}",
            f"${proper_round(bar_retail_data['retail']['6M Avg']):,}",
            f"${proper_round(kpis_main['6M Avg']):,}"
        ],
        'Items Sold': [
            f"{proper_round(bar_retail_data['bar']['Items Sold']):,}",
            f"{proper_round(bar_retail_data['retail']['Items Sold']):,}",
            f"{proper_round(kpis_main['Items Sold']):,}"
        ],
        'Inventory Value': [
            "-", "-",
            f"${proper_round(inv_value_latest):,} (as of {pd.to_datetime(inv_latest_date).strftime('%d/%m/%Y') if inv_latest_date else '-'})"
        ]

    }

    df_summary = pd.DataFrame(summary_data)

    # è®¾ç½®åˆ—é…ç½®
    column_config = {
        '': st.column_config.Column(width=80),
        'Percentage': st.column_config.Column(width=80),
        'Daily Net Sales': st.column_config.Column(width=100),
        'Daily Transactions': st.column_config.Column(width=120),
        '# of Customers': st.column_config.Column(width=100),
        'Avg Transaction': st.column_config.Column(width=105),
        '3M Avg': st.column_config.Column(width=55),
        '6M Avg': st.column_config.Column(width=55),
        'Items Sold': st.column_config.Column(width=75),
        'Inventory Value': st.column_config.Column(width=105),
    }
    # æ˜¾ç¤ºè¡¨æ ¼
    st.markdown("<h4 style='font-size:16px; font-weight:700; margin-top:1rem;'>Summary Table</h4>",
                unsafe_allow_html=True)
    st.dataframe(
        df_summary,
        column_config=column_config,
        hide_index=True,
        use_container_width=False
    )

    st.markdown("---")

    # === äº¤äº’é€‰æ‹© ===
    st.markdown("<h4 style='font-size:16px; font-weight:700;'>ğŸ” Select Parameters</h4>", unsafe_allow_html=True)

    # åˆ†ç±»é€‰æ‹©
    if category_tx is None or category_tx.empty:
        st.info("No category breakdown available.")
        return

    # è¿‡æ»¤æ‰æ²¡æœ‰æ•°æ®çš„åˆ†ç±» - ä¿®å¤é‡å¤æ˜¾ç¤ºé—®é¢˜
    category_tx["Category"] = category_tx["Category"].astype(str).str.strip()
    all_cats_tx = (
        category_tx["Category"]
        .fillna("Unknown")
        .drop_duplicates()
        .sort_values()
        .tolist()
    )

    # åªä¿ç•™æœ‰å®é™…æ•°æ®çš„åˆ†ç±»
    valid_cats = []
    seen_cats = set()
    for cat in all_cats_tx:
        if cat not in seen_cats:
            seen_cats.add(cat)
            cat_data = category_tx[category_tx["Category"] == cat]
            if not cat_data.empty and cat_data["net_sales_with_tax"].sum() > 0:
                valid_cats.append(cat)

    special_cats = ["bar", "retail", "total"]
    all_cats_extended = special_cats + sorted([c for c in valid_cats if c not in special_cats])

    # === å››ä¸ªå¤šé€‰æ¡†ä¸€è¡Œæ˜¾ç¤ºï¼ˆä½¿ç”¨ columnsï¼Œç­‰å®½ä¸”é å·¦ï¼‰ ===

    # å®šä¹‰æ¯ä¸ªæ¡†çš„å®½åº¦æ¯”ä¾‹
    col1, col2, col3, col4, _ = st.columns([1.0, 1.2, 0.8, 1.5, 2.5])

    with col1:
        time_range = persisting_multiselect(
            "Choose time range",
            ["Custom dates", "WTD", "MTD", "YTD"],
            key="hl_time",
            width_chars=15
        )

    with col2:
        data_sel_base = persisting_multiselect(
            "Choose data types",
            ["Daily Net Sales", "Weekly Net Sales", "Daily Transactions", "Avg Transaction", "Items Sold",
             "Inventory Value"],
            key="hl_data_base",
            width_chars=22
        )

    with col3:
        data_sel_avg = persisting_multiselect(
            "Choose averages",
            ["3M Avg", "6M Avg"],
            key="hl_data_avg",
            width_chars=8
        )

    with col4:
        # ä¸ºåˆ†ç±»é€‰æ‹©åˆ›å»ºè¡¨å•ï¼Œé¿å…ç«‹å³ rerun
        with st.form(key="categories_form"):
            cats_sel = st.multiselect(
                "Choose categories",
                all_cats_extended,
                default=st.session_state.get("hl_cats", []),
                key="hl_cats_widget"
            )

            # åº”ç”¨æŒ‰é’®
            submitted = st.form_submit_button("Apply", type="primary", use_container_width=True)

            if submitted:
                # æ›´æ–° session state
                st.session_state["hl_cats"] = cats_sel
                st.rerun()

        # ä» session state è·å–æœ€ç»ˆçš„é€‰æ‹©
        cats_sel = st.session_state.get("hl_cats", [])

        # æ˜¾ç¤ºå½“å‰é€‰æ‹©çŠ¶æ€
        if cats_sel:
            st.caption(f"âœ… Selected: {len(cats_sel)} categories")
        else:
            st.caption("â„¹ï¸ No categories selected")

    # åŠ ä¸€å°æ®µ CSSï¼Œè®©å››ä¸ªæ¡†å·¦å¯¹é½ã€é—´è·æœ€å°
    st.markdown("""
    <style>
    div[data-testid="column"] {
        padding: 0 4px !important;
    }
    div[data-baseweb="select"] {
        min-width: 5ch !important;
        max-width: 35ch !important;
    }
    </style>
    """, unsafe_allow_html=True)

    # åˆå¹¶æ•°æ®ç±»å‹é€‰æ‹©
    data_sel = data_sel_base.copy()

    # å¦‚æœé€‰æ‹©äº†å¹³å‡å€¼ï¼Œä¸ºæ¯ä¸ªé€‰æ‹©çš„åŸºç¡€æ•°æ®ç±»å‹æ·»åŠ å¯¹åº”çš„å¹³å‡å€¼
    for avg_type in data_sel_avg:
        for base_type in data_sel_base:
            if base_type in ["Daily Net Sales", "Weekly Net Sales", "Daily Transactions", "Avg Transaction",
                             "Items Sold"]:  # ä¿®æ”¹è¿™ä¸€è¡Œï¼Œæ·»åŠ  "Weekly Net Sales"
                combined_type = f"{base_type} {avg_type}"
                data_sel.append(combined_type)

    # å¦‚æœæ²¡æœ‰é€‰æ‹©ä»»ä½•åŸºç¡€æ•°æ®ç±»å‹ä½†æœ‰å¹³å‡å€¼ï¼Œé»˜è®¤ä½¿ç”¨Daily Net Sales
    if not data_sel_base and data_sel_avg:
        for avg_type in data_sel_avg:
            data_sel.append(f"Daily Net Sales {avg_type}")

    # === è‡ªå®šä¹‰æ—¥æœŸèŒƒå›´é€‰æ‹© ===
    custom_dates_selected = False
    t1 = None
    t2 = None

    # === ğŸ“… Custom Date Rangeï¼ˆä¿æŒåŸé€»è¾‘ + æ˜¾ç¤º dd/mm/yyyy æ ¼å¼ï¼‰ ===
    if "Custom dates" in time_range:
        custom_dates_selected = True

        # æ ‡é¢˜é£æ ¼ä¸ Select Specific Date ä¸€è‡´
        st.markdown("<h4 style='font-size:16px; font-weight:700;'>ğŸ“… Custom Date Range</h4>", unsafe_allow_html=True)

        # åˆ—å¸ƒå±€ï¼šä¸ä¸Šé¢å¤šé€‰æ¡†ç­‰å®½æ¯”ä¾‹
        col_from, col_to, _ = st.columns([1, 1, 5])

        # æ—¥æœŸè¾“å…¥æ¡† - ä¿®æ”¹ä¸º dd/mm/yy æ ¼å¼
        with col_from:
            t1 = st.date_input(
                "From",
                value=pd.Timestamp.today().normalize() - pd.Timedelta(days=7),
                key="date_from",
                format="DD/MM/YYYY"  # ä¿®æ”¹è¿™é‡Œ
            )

        with col_to:
            t2 = st.date_input(
                "To",
                value=pd.Timestamp.today().normalize(),
                key="date_to",
                format="DD/MM/YYYY"  # ä¿®æ”¹è¿™é‡Œ
            )

        # ç§»é™¤åŸæœ‰çš„JavaScriptæ ¼å¼åŒ–ä»£ç ï¼Œå› ä¸ºç°åœ¨ä½¿ç”¨å†…ç½®formatå‚æ•°

    # ä¿®æ”¹1ï¼šæ£€æŸ¥ä¸‰ä¸ªå¤šé€‰æ¡†æ˜¯å¦éƒ½æœ‰é€‰æ‹©
    has_time_range = bool(time_range)
    has_data_sel = bool(data_sel)
    has_cats_sel = bool(cats_sel)

    # å¯¹äº Custom datesï¼Œéœ€è¦ç¡®ä¿æ—¥æœŸå·²é€‰æ‹©
    if "Custom dates" in time_range:
        has_valid_custom_dates = (t1 is not None and t2 is not None)
    else:
        has_valid_custom_dates = True

    # å®æ—¶è®¡ç®—å›¾è¡¨æ•°æ® - ä¿®æ”¹1ï¼šåªæœ‰ä¸‰ä¸ªå¤šé€‰æ¡†éƒ½é€‰æ‹©äº†æ‰å±•ç¤º
    if has_time_range and has_data_sel and has_cats_sel and has_valid_custom_dates:
        with st.spinner("Generating chart..."):
            combined_df = prepare_chart_data_fast(
                daily, category_tx, inv_grouped, time_range, data_sel, cats_sel,
                custom_dates_selected, t1, t2
            )

        if combined_df is not None and not combined_df.empty:
            # ä¿®å¤ï¼šç¡®ä¿å›¾è¡¨ä¸­çš„æ—¥æœŸæŒ‰æ­£ç¡®é¡ºåºæ˜¾ç¤º
            combined_df = combined_df.sort_values("date")

            # ç«‹å³æ˜¾ç¤ºå›¾è¡¨
            fig = px.line(
                combined_df,
                x="date",
                y="value",
                color="series",
                title="All Selected Data Types by Category",
                labels={"date": "Date", "value": "Value", "series": "Series"}
            )

            # æ”¹ä¸ºæ¬§æ´²æ—¥æœŸæ ¼å¼
            fig.update_layout(
                xaxis=dict(tickformat="%d/%m/%Y"),
                hovermode="x unified",
                height=600
            )

            st.plotly_chart(fig, use_container_width=True)
            st.markdown("""
            <style>
            div[data-testid="stExpander"] > div:first-child {
                width: fit-content !important;
                max-width: 95% !important;
            }
            div[data-testid="stDataFrame"] {
                width: fit-content !important;
            }
            </style>
            """, unsafe_allow_html=True)

            # æ˜¾ç¤ºæ•°æ®è¡¨æ ¼ - ç›´æ¥å±•ç¤ºï¼Œå»æ‰ä¸‹æ‹‰æ¡†
            st.markdown("#### ğŸ“Š Combined Data for All Selected Types")
            display_df = combined_df.copy()

            # === ä¿®æ”¹ï¼šä¸º Weekly Net Sales æ˜¾ç¤ºå‘¨åŒºé—´ ===
            def format_weekly_date(row):
                if "Weekly Net Sales" in row["data_type"]:
                    # è®¡ç®—å‘¨çš„èµ·å§‹å’Œç»“æŸæ—¥æœŸï¼ˆå‘¨ä¸€åˆ°å‘¨æ—¥ï¼‰
                    week_start = row["date"]
                    week_end = week_start + pd.Timedelta(days=6)
                    # ç¡®ä¿å‘¨åŒºé—´ä¸é‡å ï¼šå¦‚æœèµ·å§‹æ—¥æœŸä¸æ˜¯å‘¨ä¸€ï¼Œè°ƒæ•´ä¸ºå‘¨ä¸€
                    if week_start.weekday() != 0:  # 0 ä»£è¡¨å‘¨ä¸€
                        week_start = week_start - pd.Timedelta(days=week_start.weekday())
                        week_end = week_start + pd.Timedelta(days=6)
                    return f"{week_start.strftime('%d/%m/%Y')}-{week_end.strftime('%d/%m/%Y')}"
                else:
                    return row["date"].strftime("%d/%m/%Y")

            display_df["date"] = display_df.apply(format_weekly_date, axis=1)

            # === ä¿®æ”¹ï¼šå¯¹è¡¨æ ¼ä¸­çš„ Daily Net Sales å’Œ Weekly Net Sales ä¹Ÿè¿›è¡Œå››èˆäº”å…¥å–æ•´ ===
            display_df.loc[display_df["data_type"].isin(["Daily Net Sales", "Weekly Net Sales"]), "value"] = \
            display_df.loc[
                display_df["data_type"].isin(["Daily Net Sales", "Weekly Net Sales"]), "value"
            ].apply(lambda x: proper_round(x) if not pd.isna(x) else 0)

            display_df = display_df.rename(columns={
                "date": "Date",
                "Category": "Category",
                "data_type": "Data Type",
                "value": "Value"
            })

            # ä¿®å¤ï¼šæŒ‰æ—¥æœŸæ­£ç¡®æ’åºï¼ˆéœ€è¦åˆ›å»ºä¸€ä¸ªä¸´æ—¶æ—¥æœŸåˆ—ç”¨äºæ’åºï¼‰
            def get_sort_date(row):
                if "Weekly Net Sales" in row["Data Type"]:
                    # ä»å‘¨åŒºé—´ä¸­æå–èµ·å§‹æ—¥æœŸ
                    start_date_str = row["Date"].split('-')[0]
                    return pd.to_datetime(start_date_str, format='%d/%m/%Y')
                else:
                    return pd.to_datetime(row["Date"], format='%d/%m/%Y')

            display_df["Date_dt"] = display_df.apply(get_sort_date, axis=1)
            display_df = display_df.sort_values(["Date_dt", "Category", "Data Type"])
            display_df = display_df.drop("Date_dt", axis=1)

            # === ä¿®æ”¹1ï¼šè¡¨æ ¼å®¹å™¨å®½åº¦è·Ÿéšè¡¨æ ¼å†…å®¹ ===
            # è®¡ç®—è¡¨æ ¼æ€»å®½åº¦
            total_width = 0
            for column in display_df.columns:
                header_len = len(str(column))
                # ä¼°ç®—åˆ—å®½ï¼šæ ‡é¢˜é•¿åº¦+æ•°æ®æœ€å¤§é•¿åº¦+2å­—ç¬¦è¾¹è·
                data_len = display_df[column].astype(str).str.len().max()
                col_width = max(header_len, data_len) + 2
                total_width += col_width

            # è®¾ç½®è¡¨æ ¼å®¹å™¨æ ·å¼
            st.markdown(f"""
            <style>
            /* è¡¨æ ¼å®¹å™¨ - å®½åº¦è·Ÿéšå†…å®¹ */
            [data-testid="stExpander"] {{
                width: auto !important;
                min-width: {total_width}ch !important;
                max-width: 100% !important;
            }}
            /* è®©è¡¨æ ¼å·¦å³å¯æ»šåŠ¨ */
            [data-testid="stDataFrame"] div[role="grid"] {{
                overflow-x: auto !important;
                width: auto !important;
            }}
            /* è‡ªåŠ¨åˆ—å®½ï¼Œä¸å¼ºåˆ¶å æ»¡ */
            [data-testid="stDataFrame"] table {{
                table-layout: auto !important;
                width: auto !important;
            }}
            /* æ‰€æœ‰å•å…ƒæ ¼å·¦å¯¹é½ */
            [data-testid="stDataFrame"] td, [data-testid="stDataFrame"] th {{
                text-align: left !important;
                justify-content: flex-start !important;
            }}
            /* é˜²æ­¢çœç•¥å· */
            [data-testid="stDataFrame"] td {{
                white-space: nowrap !important;
            }}
            </style>
            """, unsafe_allow_html=True)

            # === æ–°é€»è¾‘ï¼šåˆ—å®½æ ¹æ®æ ‡é¢˜å­—ç¬¦ä¸²é•¿åº¦è®¾ç½® ===
            column_config = {}
            for column in display_df.columns:
                header_len = len(str(column))
                column_config[column] = st.column_config.Column(
                    column,
                    width=f"{header_len + 2}ch"
                )

            # å¯¹3M/6Må¹³å‡å€¼åˆ—å››èˆäº”å…¥ä¿ç•™ä¸¤ä½å°æ•°
            avg_mask = display_df["Data Type"].str.contains("3M Avg|6M Avg", case=False, na=False)
            display_df.loc[avg_mask, "Value"] = display_df.loc[avg_mask, "Value"].apply(
                lambda x: round(x, 2) if pd.notna(x) else x
            )

            # æ–°å¢ï¼šå¯¹ Weekly Net Sales ä¹Ÿè¿›è¡Œå››èˆäº”å…¥å–æ•´
            weekly_mask = display_df["Data Type"].str.contains("Weekly Net Sales", case=False, na=False) & ~display_df[
                "Data Type"].str.contains("Avg", case=False, na=False)
            display_df.loc[weekly_mask, "Value"] = display_df.loc[weekly_mask, "Value"].apply(
                lambda x: proper_round(x) if not pd.isna(x) else 0
            )

            st.dataframe(display_df, use_container_width=False, column_config=column_config)

        else:
            st.warning("No data available for the selected combination.")
