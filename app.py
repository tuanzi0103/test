import streamlit as st

st.set_page_config(
    page_title="Vie Manly Analytics",
    layout="wide",
    initial_sidebar_state="auto"
)

import warnings
warnings.simplefilter("ignore")

import os
import pandas as pd
from services.analytics import load_all
from services.db import get_db
from services.ingestion import ingest_excel, ingest_csv, init_db_from_drive_once
from charts.high_level import show_high_level
from charts.sales_report import show_sales_report
from charts.inventory import show_inventory
from charts.product_mix_only import show_product_mix_only
from charts.customer_segmentation import show_customer_segmentation
from init_db import init_db
import subprocess
import sys
from services.ingestion import ingest_from_drive_all
import platform
import numpy as np
from datetime import datetime, timedelta

import psutil

def check_memory():
    mem = psutil.virtual_memory()
    used_gb = mem.used / (1024 ** 3)
    total_gb = mem.total / (1024 ** 3)
    usage_ratio = used_gb / total_gb

    if usage_ratio > 0.85:
        st.warning(f"âš ï¸ Memory usage high ({usage_ratio*100:.1f}%). Please refresh occasionally.")



# å…³é—­æ–‡ä»¶ç›‘æ§ï¼Œé¿å… Streamlit Cloud æŠ¥ inotify é”™è¯¯
os.environ["WATCHDOG_DISABLE_FILE_WATCH"] = "true"

# âœ… ç¡®ä¿ SQLite æ–‡ä»¶å’Œè¡¨ç»“æ„å­˜åœ¨
init_db()  # å¿…é¡»å…ˆåˆå§‹åŒ–æ•°æ®åº“è¡¨ç»“æ„

if "drive_initialized" not in st.session_state:
    init_db_from_drive_once()
    st.session_state.drive_initialized = True


st.markdown("<h1 style='font-size:26px; font-weight:700;'>ğŸ“Š Vie Manly Dashboard</h1>", unsafe_allow_html=True)


# âœ… ç¼“å­˜æ•°æ®åº“åŠ è½½
@st.cache_data(show_spinner="loading...")
def load_db_cached(days=365):
    db = get_db()
    return load_all(db=db)


# === æ•°æ®ç¼ºå¤±æ£€æŸ¥å‡½æ•° ===
def check_missing_data(tx, inv):
    """æ£€æŸ¥ä»2025-11-01å¼€å§‹ç¼ºå¤±çš„æ•°æ®æ—¥æœŸ"""
    missing_info = {
        'transaction_dates': [],
        'inventory_dates': []
    }

    # è®¾ç½®æ£€æŸ¥çš„èµ·å§‹æ—¥æœŸ
    start_date = datetime(2025, 11, 1).date()
    end_date = datetime.now().date()

    # æ£€æŸ¥äº¤æ˜“æ•°æ®ç¼ºå¤±
    if tx is not None and not tx.empty and 'Datetime' in tx.columns:
        # è½¬æ¢æ—¥æœŸåˆ—
        tx_dates = pd.to_datetime(tx['Datetime'], errors='coerce').dt.date
        tx_dates = tx_dates.dropna().unique()

        # ç”Ÿæˆæ‰€æœ‰åº”è¯¥æœ‰çš„æ—¥æœŸ
        all_dates = [start_date + timedelta(days=x) for x in range((end_date - start_date).days + 1)]

        # æ‰¾å‡ºç¼ºå¤±çš„æ—¥æœŸ
        for date in all_dates:
            if date not in tx_dates:
                missing_info['transaction_dates'].append(date)

    # æ£€æŸ¥åº“å­˜æ•°æ®ç¼ºå¤±
    if inv is not None and not inv.empty and 'source_date' in inv.columns:
        # è½¬æ¢æ—¥æœŸåˆ—
        inv_dates = pd.to_datetime(inv['source_date'], errors='coerce').dt.date
        inv_dates = inv_dates.dropna().unique()

        # ç”Ÿæˆæ‰€æœ‰åº”è¯¥æœ‰çš„æ—¥æœŸ
        all_dates = [start_date + timedelta(days=x) for x in range((end_date - start_date).days + 1)]

        # æ‰¾å‡ºç¼ºå¤±çš„æ—¥æœŸ
        for date in all_dates:
            if date not in inv_dates:
                missing_info['inventory_dates'].append(date)

    return missing_info


# === æ•°æ®åŠ è½½ ===
if "db_cache" not in st.session_state:
    st.session_state.db_cache = load_db_cached()
tx, mem, inv = st.session_state.db_cache


# === Sidebar ===
st.sidebar.header("âš™ï¸ Settings")

# === æ•°æ®ç¼ºå¤±é¢„è­¦ ===
missing_data = check_missing_data(tx, inv)

if missing_data['transaction_dates'] or missing_data['inventory_dates']:
    st.sidebar.markdown("---")
    st.sidebar.markdown("### âš ï¸ Data missing warning")

    if missing_data['transaction_dates']:
        st.sidebar.error("**Missing transaction date:**")
        # æ˜¾ç¤ºæœ€è¿‘7å¤©çš„ç¼ºå¤±æ—¥æœŸï¼Œå…¶ä»–çš„æŠ˜å æ˜¾ç¤º
        recent_missing = sorted(missing_data['transaction_dates'])[-7:]
        for date in recent_missing:
            st.sidebar.write(f"ğŸ“… {date.strftime('%Y-%m-%d')}")

        if len(missing_data['transaction_dates']) > 7:
            with st.sidebar.expander(f"check all {len(missing_data['transaction_dates'])} missing dates"):
                for date in sorted(missing_data['transaction_dates']):
                    st.write(f"ğŸ“… {date.strftime('%Y-%m-%d')}")

    if missing_data['inventory_dates']:
        st.sidebar.warning("**Missing inventory date:**")
        # æ˜¾ç¤ºæœ€è¿‘7å¤©çš„ç¼ºå¤±æ—¥æœŸï¼Œå…¶ä»–çš„æŠ˜å æ˜¾ç¤º
        recent_missing = sorted(missing_data['inventory_dates'])[-7:]
        for date in recent_missing:
            st.sidebar.write(f"ğŸ“¦ {date.strftime('%Y-%m-%d')}")

        if len(missing_data['inventory_dates']) > 7:
            with st.sidebar.expander(f"check all {len(missing_data['inventory_dates'])} missing dates"):
                for date in sorted(missing_data['inventory_dates']):
                    st.write(f"ğŸ“¦ {date.strftime('%Y-%m-%d')}")

# æ–‡ä»¶ä¸Šä¼  - æ·»åŠ ä¸Šä¼ çŠ¶æ€è·Ÿè¸ª
if "uploaded_file_names" not in st.session_state:
    st.session_state.uploaded_file_names = set()

uploaded_files = st.sidebar.file_uploader(
    "Upload files",
    type=["csv", "xlsx"],
    accept_multiple_files=True
)

# âœ… ä¿®å¤ä¸Šä¼ é€»è¾‘ï¼šé¿å…é‡å¤ä¸Šä¼ 
if uploaded_files:
    db = get_db()
    new_files_uploaded = False

    for f in uploaded_files:
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²ç»ä¸Šä¼ è¿‡
        if f.name not in st.session_state.uploaded_file_names:
            try:
                if f.name.lower().endswith(".xlsx"):
                    ingest_excel(f)
                    new_files_uploaded = True
                    st.session_state.uploaded_file_names.add(f.name)
                    st.sidebar.info(f"ğŸ“¥ Processing: {f.name}")
                elif f.name.lower().endswith(".csv"):
                    ingest_csv(f)
                    new_files_uploaded = True
                    st.session_state.uploaded_file_names.add(f.name)
                    st.sidebar.info(f"ğŸ“¥ Processing: {f.name}")
            except Exception as e:
                st.sidebar.error(f"âŒ Error processing {f.name}: {e}")
        else:
            st.sidebar.warning(f"âš ï¸ {f.name} already uploaded")

    if new_files_uploaded:
        st.sidebar.success("âœ… Files ingested & uploaded to Google Drive.")
        # æ¸…ç†ç¼“å­˜ â†’ é‡æ–°åŠ è½½æ•°æ®åº“
        load_db_cached.clear()
        st.session_state.db_cache = load_db_cached()
        tx, mem, inv = st.session_state.db_cache

        # è®¾ç½®åˆ·æ–°æ ‡å¿—é˜²æ­¢æ­»å¾ªç¯
        if "reloaded" not in st.session_state:
            st.session_state["reloaded"] = True
            st.rerun()
        else:
            del st.session_state["reloaded"]

# === æ¸…ç©ºæ•°æ®åº“ ===
if st.sidebar.button("ğŸ—‘ï¸ Clear Database"):
    conn = get_db()
    cur = conn.cursor()
    for table in ["transactions", "inventory", "members"]:
        try:
            cur.execute(f"DELETE FROM {table}")
        except Exception:
            pass
    conn.commit()
    # æ¸…ç©ºä¸Šä¼ è®°å½•
    st.session_state.uploaded_file_names = set()
    st.sidebar.success("âœ… Database cleared!")
    load_db_cached.clear()
    st.session_state.db_cache = load_db_cached()
    tx, mem, inv = st.session_state.db_cache
    st.rerun()

# === é‡å¯åº”ç”¨æŒ‰é’® ===
if st.sidebar.button("ğŸ”„ Restart & Reload App"):
    try:
        # 1. æ¸…é™¤ Streamlit ç¼“å­˜
        st.cache_data.clear()
        st.cache_resource.clear()

        # 2. æ¸…ç©ºä¸Šä¼ çŠ¶æ€
        if "uploaded_file_names" in st.session_state:
            del st.session_state.uploaded_file_names

        # 3. é‡æ–°ä» Google Drive å¯¼å…¥æ‰€æœ‰æ•°æ®ï¼ˆåŒ…æ‹¬æ–°ä¸Šä¼ çš„ï¼‰
        st.sidebar.info("ğŸ”„ Reloading data from Google Drive...")
        ingest_from_drive_all()

        # 4. é‡æ–°åŠ è½½æ•°æ®
        load_db_cached.clear()
        st.session_state.db_cache = load_db_cached()
        tx, mem, inv = st.session_state.db_cache

        st.sidebar.success("âœ… App restarted with latest data!")
        st.rerun()

    except Exception as e:
        st.sidebar.error(f"âŒ Restart failed: {e}")

# === å•ä½é€‰æ‹© ===
st.sidebar.subheader("ğŸ“ Units")

if inv is not None and not inv.empty and "Unit" in inv.columns:
    units_available = sorted(inv["Unit"].dropna().unique().tolist())
else:
    units_available = ["Gram 1.000", "Kilogram 1.000", "Milligram 1.000"]

conn = get_db()
try:
    rows = conn.execute("SELECT name FROM units").fetchall()
    db_units = [r[0] for r in rows]  # ä¿®å¤è¿™é‡Œçš„ç´¢å¼•é”™è¯¯
except Exception:
    db_units = []

all_units = sorted(list(set(units_available + db_units)))
unit = st.sidebar.selectbox("Choose unit", all_units)

new_unit = st.sidebar.text_input("Add new unit")
if st.sidebar.button("â• Add Unit"):
    if new_unit and new_unit not in all_units:
        conn.execute("CREATE TABLE IF NOT EXISTS units (name TEXT UNIQUE)")
        conn.execute("INSERT OR IGNORE INTO units (name) VALUES (?)", (new_unit,))
        conn.commit()
        st.sidebar.success(f"âœ… Added new unit: {new_unit}")
        st.rerun()

# === Section é€‰æ‹© ===
section = st.sidebar.radio("ğŸ“‚ Sections", [
    "High Level report",
    "Sales report by category",
    "Inventory",
    "product mix",
    "Customers insights"
])

# === ä¸»ä½“å±•ç¤º ===
if section == "High Level report":
    show_high_level(tx, mem, inv)
elif section == "Sales report by category":
    show_sales_report(tx, inv)
elif section == "Inventory":
    show_inventory(tx, inv)
elif section == "product mix":
    show_product_mix_only(tx)
elif section == "Customers insights":
    show_customer_segmentation(tx, mem)